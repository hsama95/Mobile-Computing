{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "import ast\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(X, y):\n",
    "    # input: image and landmark coordinates\n",
    "    # output: plot the labelled image\n",
    "    X = X.reshape((256, 256, 3))\n",
    "    y = 256 * y.reshape((194, 2))\n",
    "    for i in range(y.shape[0]):\n",
    "        for l in [-1, 0, 1]:\n",
    "            for r in [-1, 0, 1]:\n",
    "                X[y[i, 1] + l, y[i, 0] + r, 0] = 0\n",
    "                X[y[i, 1] + l, y[i, 0] + r, 1] = 0\n",
    "                X[y[i, 1] + l, y[i, 0] + r, 2] = 255\n",
    "                \n",
    "    plt.imshow(X[:,:,::-1])\n",
    "    plt.show()\n",
    "\n",
    "# get Y of an image\n",
    "def load_y(file_prefix):\n",
    "    # input: string; a prefix\n",
    "    # output: np array of size 194 * 2; corresponding landmark coordinates\n",
    "    path = 'D:\\\\Research\\\\Structure_1\\\\data\\\\'\n",
    "    filename = path + file_prefix + '_coordinate'\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        facebox = f.readlines()\n",
    "    facebox = ast.literal_eval(facebox[0])\n",
    "    \n",
    "    with open(path + file_prefix + '.txt', 'r') as f:\n",
    "        index = f.readlines()\n",
    "    \n",
    "    coordinate = []\n",
    "\n",
    "    for item in index[1:]:\n",
    "        coordinate.append( list(map(float, item.strip('\\n').split(','))))\n",
    "        \n",
    "    coordinate = np.round(np.array(coordinate)).astype(int)\n",
    "\n",
    "    coordinate[:,0] -= facebox[0]\n",
    "    coordinate[:,1] -= facebox[1]\n",
    "\n",
    "    width = facebox[2] - facebox[0]\n",
    "    height = facebox[3] - facebox[1]\n",
    "\n",
    "    coordinate[:, 0] = coordinate[:, 0] / width * 256\n",
    "    coordinate[:, 1] = coordinate[:, 1] / height * 256\n",
    "    \n",
    "    return coordinate.reshape((1, 194 * 2))\n",
    "\n",
    "# get X of an image\n",
    "def load_X(file_prefix):\n",
    "    # input: string; a prefix\n",
    "    # output: np array of size 194 * 194 * 3 by 1;\n",
    "    path = 'D:\\\\Research\\\\Structure_1\\\\data\\\\'\n",
    "    return cv2.imread(path + file_prefix + \"_face.jpg\").reshape((1, 256 * 256 * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file prefix \n",
    "with open('filename.txt', 'r') as f:\n",
    "    filename = f.readlines()\n",
    "\n",
    "file_prefix_set = []\n",
    "for item in filename:\n",
    "    file_prefix_set.append(item.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epoch = 200\n",
    "batch_size = 20\n",
    "display_step = 1\n",
    "save_step = 10\n",
    "training_size = 1800\n",
    "validation_size = 200\n",
    "test_size = 223\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 256 # image size\n",
    "num_channel = 3 # number of channel\n",
    "num_output = 194 * 2 # coordinate size\n",
    "\n",
    "# tf Graph input\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, num_input * num_input * num_channel], name = 'X')\n",
    "X_image = tf.reshape(X, [-1, num_input, num_input, num_channel])\n",
    "y = tf.placeholder(tf.float32, [None, num_output], name = 'y')\n",
    "keep_prob_1 = tf.placeholder(tf.float32, name = 'keep_prob_1')\n",
    "keep_prob_2 = tf.placeholder(tf.float32, name = 'keep_prob_2')\n",
    "keep_prob_3 = tf.placeholder(tf.float32, name = 'keep_prob_3')\n",
    "keep_prob_4 = tf.placeholder(tf.float32, name = 'keep_prob_4')\n",
    "\n",
    "def CNN(x):\n",
    "    conv_1 = tf.layers.conv2d(inputs = x,\n",
    "                              filters = 32,\n",
    "                              kernel_size = [3, 3],\n",
    "                              strides = (1, 1),\n",
    "                              padding = 'valid',\n",
    "                              activation = tf.nn.relu)\n",
    "    \n",
    "    pool_1 = tf.layers.max_pooling2d(inputs = conv_1,\n",
    "                                     pool_size = [2, 2],\n",
    "                                     strides = (2, 2),\n",
    "                                     padding = 'valid')\n",
    "    \n",
    "    drop_out_1 = tf.nn.dropout(pool_1, keep_prob_1)\n",
    "    \n",
    "    conv_2 = tf.layers.conv2d(inputs = drop_out_1,\n",
    "                              filters = 64,\n",
    "                              kernel_size = [3, 3],\n",
    "                              strides = (1, 1),\n",
    "                              padding = 'valid',\n",
    "                              activation = tf.nn.relu)\n",
    "    \n",
    "    conv_3 = tf.layers.conv2d(inputs = conv_2,\n",
    "                              filters = 64,\n",
    "                              kernel_size = [3, 3],\n",
    "                              strides = (1, 1),\n",
    "                              padding = 'valid',\n",
    "                              activation = tf.nn.relu)\n",
    "    \n",
    "    pool_2 = tf.layers.max_pooling2d(inputs = conv_3,\n",
    "                                     pool_size = [2, 2],\n",
    "                                     strides = (2, 2),\n",
    "                                     padding = 'valid')\n",
    "    \n",
    "    drop_out_2 = tf.nn.dropout(pool_2, keep_prob_2)\n",
    "    \n",
    "    conv_4 = tf.layers.conv2d(inputs = drop_out_2,\n",
    "                              filters = 64,\n",
    "                              kernel_size = [3, 3],\n",
    "                              strides = (1, 1),\n",
    "                              padding = 'valid',\n",
    "                              activation = tf.nn.relu)\n",
    "    \n",
    "    conv_5 = tf.layers.conv2d(inputs = conv_4,\n",
    "                              filters = 64,\n",
    "                              kernel_size = [3, 3],\n",
    "                              strides = (1, 1),\n",
    "                              padding = 'valid',\n",
    "                              activation = tf.nn.relu)\n",
    "    \n",
    "    pool_3 = tf.layers.max_pooling2d(inputs = conv_5,\n",
    "                                     pool_size = [2, 2],\n",
    "                                     strides = (2, 2),\n",
    "                                     padding = 'valid')\n",
    "    \n",
    "    drop_out_3 = tf.nn.dropout(pool_3, keep_prob_3)\n",
    "\n",
    "    flatten = tf.layers.flatten(inputs = drop_out_3)\n",
    "    \n",
    "    fc_1 = tf.layers.dense(inputs = flatten,\n",
    "                           units = 1024,\n",
    "                           activation = tf.nn.relu,\n",
    "                           use_bias=True)\n",
    "    \n",
    "    drop_out_4 = tf.nn.dropout(fc_1, keep_prob_4)\n",
    "\n",
    "    logits = tf.layers.dense(inputs = drop_out_4,\n",
    "                             units = 194 * 2,\n",
    "                             activation = None,\n",
    "                             use_bias = True,\n",
    "                             name = 'logits')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = CNN(X_image)\n",
    "label_tensor = tf.convert_to_tensor(y, dtype = tf.float32)\n",
    "loss = tf.losses.mean_squared_error(labels = label_tensor, predictions = logits)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "coordinate = tf.identity(logits, name = 'coordinate')\n",
    "\n",
    "# Initialize the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_index = np.random.permutation(len(file_prefix_set))\n",
    "total_index = np.loadtxt('total_index.txt').astype('int')\n",
    "training_index = total_index[:training_size]\n",
    "validation_index = total_index[training_size : training_size + validation_size]\n",
    "test_index = total_index[training_size + validation_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.3515153939279014, Validation Loss: 7.068358505889005\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 1, Training Loss: 2.3547213474112207, Validation Loss: 7.08250366598641\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 2, Training Loss: 2.4173264631241653, Validation Loss: 7.272576214445736\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 3, Training Loss: 2.2132385969505437, Validation Loss: 6.663903510064883\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 4, Training Loss: 2.3004562164298927, Validation Loss: 6.9172513532601725\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 5, Training Loss: 2.2573810001467933, Validation Loss: 6.7870359272105\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 6, Training Loss: 2.1753491250504338, Validation Loss: 6.5461139581343115\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 7, Training Loss: 2.1424458119448118, Validation Loss: 6.455424434970959\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 8, Training Loss: 2.1409660588570083, Validation Loss: 6.43863694355552\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 9, Training Loss: 2.0600465190106263, Validation Loss: 6.201432390689191\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 10, Training Loss: 2.0916617414470817, Validation Loss: 6.296443403710766\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 11, Training Loss: 1.886895072080568, Validation Loss: 5.709250061171461\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 12, Training Loss: 2.1090689615133513, Validation Loss: 6.3597665391214555\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 13, Training Loss: 1.9316104308251285, Validation Loss: 5.832090319631366\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 14, Training Loss: 1.8773735241457121, Validation Loss: 5.670867119741963\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 15, Training Loss: 1.8370847642491355, Validation Loss: 5.543009628796804\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 16, Training Loss: 1.8557339488028424, Validation Loss: 5.611838445403136\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 17, Training Loss: 1.8539619572618697, Validation Loss: 5.603662681060954\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 18, Training Loss: 1.9118535289756775, Validation Loss: 5.782918134547549\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 19, Training Loss: 1.8376561020662663, Validation Loss: 5.564111643899024\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 20, Training Loss: 1.8574118614313817, Validation Loss: 5.627906834704925\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 21, Training Loss: 1.8528452943837341, Validation Loss: 5.619400756084487\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 22, Training Loss: 1.8391769943609266, Validation Loss: 5.576977969865686\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 23, Training Loss: 1.8465457204707576, Validation Loss: 5.603948096765372\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 24, Training Loss: 1.7924109663317846, Validation Loss: 5.448483720553283\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 25, Training Loss: 1.8456418860888795, Validation Loss: 5.585406234775104\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 26, Training Loss: 1.7936191618667812, Validation Loss: 5.448979714354281\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 27, Training Loss: 1.7626193157745778, Validation Loss: 5.353379572260503\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 28, Training Loss: 1.8262889870928336, Validation Loss: 5.560425044697919\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 29, Training Loss: 1.684540255060393, Validation Loss: 5.133023018961307\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 30, Training Loss: 1.7758865313099528, Validation Loss: 5.405471818923355\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 31, Training Loss: 1.7493195759190072, Validation Loss: 5.320410276489738\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 32, Training Loss: 1.710864714646971, Validation Loss: 5.198081723567736\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 33, Training Loss: 1.6497019824309993, Validation Loss: 5.016219151903706\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 34, Training Loss: 1.627084649060547, Validation Loss: 4.966980972781985\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch: 35, Training Loss: 1.643964207401944, Validation Loss: 5.0061279294946175\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# record training loss and validation loss\n",
    "trainRecord = []\n",
    "validationRecord = []\n",
    "\n",
    "# Training\n",
    "saver = tf.train.Saver(max_to_keep = training_epoch)\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        \n",
    "        # number of steps for each epoch\n",
    "        total_batch = int(len(training_index) / batch_size)\n",
    "        \n",
    "        # shuffle index and create batches\n",
    "        index = np.random.permutation(training_index)\n",
    "        \n",
    "        start = 0\n",
    "        \n",
    "        # go through every batch for training\n",
    "        for i in range(total_batch):\n",
    "            batch_X = np.zeros((batch_size, num_input * num_input * num_channel))\n",
    "            batch_y = np.zeros((batch_size, num_output)) \n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                batch_X[j, :] = load_X(file_prefix_set[index[i * batch_size + j]])\n",
    "                batch_y[j, :] = load_y(file_prefix_set[index[i * batch_size + j]])\n",
    "\n",
    "            sess.run(optimizer, feed_dict = {X: batch_X, y: batch_y, keep_prob_1 : 0.8, keep_prob_2 : 0.8, \n",
    "                                             keep_prob_3 : 0.8, keep_prob_4 : 0.8})\n",
    "        \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            \n",
    "            training_loss = 0\n",
    "            for i in range(len(training_index)):\n",
    "                train_X = load_X(file_prefix_set[training_index[i]])\n",
    "                train_y = load_y(file_prefix_set[training_index[i]])\n",
    "                training_loss += sess.run(loss, feed_dict = {X: train_X, y: train_y, keep_prob_1 : 1, keep_prob_2 : 1, \n",
    "                                                             keep_prob_3 : 1, keep_prob_4 : 1})\n",
    "            trainRecord.append(training_loss ** 0.5 / len(training_index))\n",
    "\n",
    "            validation_loss = 0\n",
    "            for i in range(len(validation_index)):\n",
    "                validation_X = load_X(file_prefix_set[validation_index[i]])\n",
    "                validation_y = load_y(file_prefix_set[validation_index[i]])\n",
    "                validation_loss += sess.run(loss, feed_dict = {X: validation_X, y: validation_y, keep_prob_1 : 1, keep_prob_2 : 1, \n",
    "                                                               keep_prob_3 : 1, keep_prob_4 : 1})\n",
    "            validationRecord.append(validation_loss ** 0.5 / len(validation_index))\n",
    "                        \n",
    "            print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, trainRecord[-1], validationRecord[-1]))\n",
    "        \n",
    "            print('-----------------------------------------------------------------------------------------')\n",
    "            \n",
    "        if (epoch + 1) % save_step == 0:\n",
    "            # Save model\n",
    "            filename = 'D:\\Research\\Structure_1\\model\\CNN_Epoch_' + str(epoch + 1) + '.ckpt'\n",
    "            saver.save(sess, filename)\n",
    "\n",
    "print('Training Finished.')\n",
    "end_time = time.time()\n",
    "print('Training Time: {} seconds'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "patternTrain = go.Scatter(x = list(range(len(trainRecord))), y = np.array(trainRecord), mode = 'markers + lines', name = 'Training')  \n",
    "patternValidation = go.Scatter(x = list(range(len(validationRecord))), y = np.array(validationRecord), mode = 'markers + lines', name = 'Validation')  \n",
    "\n",
    "# plot   \n",
    "plot_data = [patternTrain, patternValidation]\n",
    "\n",
    "layout = go.Layout(xaxis = dict(showgrid=True,\n",
    "                              gridcolor='#bdbdbd',\n",
    "                              gridwidth=0.1,\n",
    "                              title = 'Epochs'),\n",
    "                   yaxis = dict(showgrid=True,\n",
    "                              gridcolor='#bdbdbd',\n",
    "                              gridwidth=0.1,\n",
    "                              title = 'Loss')\n",
    "    )\n",
    "fig = go.Figure(data = plot_data, layout = layout)\n",
    "offline.iplot(fig)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.array(validationRecord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
